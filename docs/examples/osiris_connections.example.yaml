# Osiris Connections Configuration
#
# This file defines connection aliases for different data sources.
# Secrets should be stored in .env and referenced via ${ENV_VAR} syntax.
#
# To use this file:
# 1. Copy to osiris_connections.yaml in your project root
# 2. Update connection details for your environment
# 3. Set referenced environment variables in .env file
#
# Connection Selection:
# - In OML: Use "@family.alias" (e.g., "@mysql.production")
# - If not specified, the default connection for that family is used
# - Default precedence: 1) default: true, 2) alias named "default", 3) error

version: 1

connections:
  # MySQL Database Connections
  mysql:
    # Movies database (development)
    db_movies:
      default: true  # This will be used when no connection specified
      host: test-api-to-mysql.cjtmwuzxk8bh.us-east-1.rds.amazonaws.com
      port: 3306
      database: padak
      user: admin
      password: ${MYSQL_PASSWORD}  # Set in .env file
      # Optional connection pool settings
      pool_size: 5
      max_overflow: 10

    # Analytics database (production)
    db_analytics:
      host: mysql-analytics.prod.internal
      port: 3306
      database: analytics
      user: svc_analytics
      password: ${MYSQL_ANALYTICS_PASSWORD}
      ssl_ca: /path/to/ca.pem  # Optional SSL certificate
      pool_size: 10
      max_overflow: 20

    # Local development MySQL
    local:
      host: localhost
      port: 3306
      database: test_db
      user: root
      password: ${MYSQL_LOCAL_PASSWORD}

  # Supabase Connections
  supabase:
    # Main production instance
    main:
      default: true
      url: https://nedklmkgzjsyvqfxbmve.supabase.com
      service_role_key: ${SUPABASE_SERVICE_ROLE_KEY}
      # Optional: specify particular schemas or settings
      schema: public

    # Staging environment
    staging:
      url: https://staging-xyz.supabase.com
      service_role_key: ${SUPABASE_STAGING_KEY}
      schema: staging

    # Development environment
    development:
      url: http://localhost:54321  # Local Supabase instance
      service_role_key: ${SUPABASE_DEV_KEY}
      anon_key: ${SUPABASE_DEV_ANON_KEY}  # Optional public key

  # DuckDB Connections
  duckdb:
    # Local file-based database
    local:
      default: true
      path: ./data/local.duckdb
      read_only: false

    # In-memory database for testing
    memory:
      path: ":memory:"
      read_only: false

    # Shared read-only analytics database
    analytics:
      path: /shared/analytics/main.duckdb
      read_only: true

  # PostgreSQL Connections (future)
  postgresql:
    warehouse:
      host: postgres.warehouse.internal
      port: 5432
      database: warehouse
      user: etl_user
      password: ${POSTGRES_WAREHOUSE_PASSWORD}
      sslmode: require

  # Snowflake Connections (future)
  snowflake:
    analytics:
      account: mycompany
      warehouse: COMPUTE_WH
      database: ANALYTICS
      schema: PUBLIC
      user: etl_service
      password: ${SNOWFLAKE_PASSWORD}
      role: ETL_ROLE

  # S3 Connections (future)
  s3:
    data_lake:
      default: true
      bucket: company-data-lake
      region: us-east-1
      access_key_id: ${AWS_ACCESS_KEY_ID}
      secret_access_key: ${AWS_SECRET_ACCESS_KEY}
      # Optional: assume role for cross-account access
      role_arn: arn:aws:iam::123456789012:role/DataLakeReader

    backup:
      bucket: company-backups
      region: eu-west-1
      access_key_id: ${AWS_BACKUP_ACCESS_KEY}
      secret_access_key: ${AWS_BACKUP_SECRET_KEY}

# Connection Groups (future enhancement)
# Allow logical grouping of connections for multi-step operations
groups:
  etl_pipeline:
    description: "Standard ETL from MySQL to Supabase"
    connections:
      - mysql.db_analytics
      - supabase.main

  local_dev:
    description: "Local development setup"
    connections:
      - mysql.local
      - duckdb.memory
      - supabase.development
