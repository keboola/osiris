#!/usr/bin/env python3
"""
Osiris Agent Terminal Session Simulator
Demonstrates OML generation for lapsed customer reactivation
"""

import hashlib
import random
import sys
import time
from datetime import datetime
from pathlib import Path

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

# Deterministic setup
random.seed(42)
console = Console()

# Paths
BASE_DIR = Path(__file__).parent
ASSETS_DIR = BASE_DIR / "assets"
OUT_DIR = BASE_DIR / "out"
OUT_DIR.mkdir(exist_ok=True)


def typewrite(text: str, min_cps: int = 30, max_cps: int = 45):
    """Simulate typing effect with deterministic random delays."""
    cps = random.uniform(min_cps, max_cps)
    delay = 1.0 / cps

    for char in text:
        console.print(char, end="", style="bright_white")
        time.sleep(delay * random.uniform(0.8, 1.2))
    console.print()  # newline


def agent_say(message: str, style: str = "dim cyan"):
    """Agent messages appear instantly with style."""
    console.print(f"[{style}]agent:[/] {message}")
    time.sleep(random.uniform(0.15, 0.35))


def user_say(message: str):
    """User messages with typing effect."""
    console.print("[bright_white]you:[/] ", end="")
    typewrite(message)
    time.sleep(random.uniform(0.3, 0.5))


def spinner_task(message: str, duration: float = None):
    """Show a spinner for a task."""
    if duration is None:
        duration = random.uniform(0.6, 1.1)

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
        transient=True,
    ) as progress:
        task = progress.add_task(message, total=100)
        steps = 20
        for _ in range(steps):
            time.sleep(duration / steps)
            progress.advance(task, 100 / steps)
    console.print(f"{message} [green]OK[/]")


def auto_approve(prompt: str = "Press Enter to approve", delay: float = 1.2):
    """Simulate approval prompt that auto-advances."""
    console.print(f"[[yellow]{prompt}[/]]", end="")
    time.sleep(delay)
    console.print(" [green]✓[/]")


def render_oml():
    """Render OML from template."""
    timestamp = datetime.now().isoformat()
    run_hash = hashlib.md5(f"lapsed-{timestamp}".encode()).hexdigest()[:8]

    oml_content = f"""# Generated by Osiris Agent
# Timestamp: {timestamp}
# Run ID: {run_hash}

version: 1
pipeline:
  name: lapsed_customers_reactivation
  region: eu-central

stages:
  ingest:
    - name: extract_supabase
      type: supabase.extractor
      config:
        table: customers
        select: "*"
        filters:
          - column: updated_at
            operator: ">="
            value: "{{{{ start_date }}}}"

    - name: extract_stripe
      type: stripe.extractor
      config:
        object: customers
        expand: ["subscriptions", "charges"]
        created: "{{{{ stripe_since }}}}"

    - name: extract_mixpanel
      type: mixpanel.extractor
      config:
        from_date: "{{{{ lookback_90d }}}}"
        to_date: "{{{{ today }}}}"
        event: ["Purchase", "PageView", "AddToCart"]

    - name: extract_shopify
      type: shopify.extractor
      config:
        resource: orders
        status: "any"
        created_at_min: "{{{{ lookback_365d }}}}"
        fields: ["id", "email", "total_price", "created_at", "line_items"]

    - name: extract_zendesk
      type: zendesk.extractor
      config:
        resource: tickets
        updated_since: "{{{{ lookback_180d }}}}"
        include: ["users", "comments"]

  identity_resolution:
    - name: identity_matching
      type: identity.matcher
      config:
        sources:
          - supabase: email
          - stripe: email
          - mixpanel: distinct_id
          - shopify: email
          - zendesk: requester_email
        match_rules:
          - type: deterministic
            fields: ["email", "phone"]
          - type: fuzzy_email
            threshold: 0.85
        output: unified_customer_id

  features:
    - name: rfm_scoring
      type: duckdb.transform
      config:
        sql_file: features/rfm.sql
        inputs: ["identity_matching"]
        output: rfm_scores

    - name: churn_prediction
      type: duckdb.transform
      config:
        sql_file: features/churn_score.sql
        inputs: ["rfm_scores", "extract_mixpanel"]
        output: churn_scores

    - name: support_topics
      type: duckdb.transform
      config:
        sql_file: features/topics.sql
        inputs: ["extract_zendesk"]
        output: support_topics

  segments:
    - name: lapsed_90
      type: duckdb.transform
      config:
        sql_file: segments/lapsed_90.sql
        inputs: ["churn_scores"]
        output: segment_lapsed_90

    - name: lapsed_vip
      type: duckdb.transform
      config:
        sql_file: segments/lapsed_vip.sql
        inputs: ["rfm_scores", "churn_scores"]
        output: segment_lapsed_vip

    - name: high_churn_risk
      type: duckdb.transform
      config:
        sql_file: segments/high_churn_risk.sql
        inputs: ["churn_scores", "support_topics"]
        output: segment_churn_risk_high

  dq:
    - name: quality_checks
      type: dq.guardian
      config:
        rules:
          - type: null_ratio
            threshold: 0.02
            columns: ["email", "unified_customer_id", "last_purchase_date"]
          - type: uniqueness
            table: orders
            column: order_id
          - type: schema_drift
            source: mixpanel_events
            alert_on_new_columns: true
          - type: business_check
            expression: "COUNT(CASE WHEN last_purchase_date > CURRENT_DATE THEN 1 END) = 0"
            error_message: "Future dated purchases detected"

  activation:
    - name: google_ads_upload
      type: google_ads.writer
      config:
        audience: lapsed90
        holdout: 0.10
        frequency_cap_per_week: 3
        campaign: "Win-Back Q1 2025"

    - name: esp_campaign
      type: esp.writer
      config:
        segment: segment_churn_risk_high
        template: recovery_with_reason_codes
        schedule: "0 10 * * *"  # Daily 10am
        a_b_test:
          enabled: true
          variants: ["subject_line_a", "subject_line_b"]

  publish:
    - name: iceberg_write
      type: iceberg.writer
      config:
        database: marketing
        table: customers_curated
        mode: append
        partition_by: ["updated_date"]
        sort_by: ["unified_customer_id"]

privacy:
  pii_mask_preview: true
  consent_filter: required
  data_residency: eu

agents:
  dq_guardian:
    webhook: "https://hooks.osiris.io/dq/{{{{ pipeline_id }}}}"
    on_warning: notify
    on_failure: halt
"""

    oml_path = OUT_DIR / "OML.yaml"
    oml_path.write_text(oml_content)
    return oml_path, run_hash


def generate_run_report(run_hash: str):
    """Generate a summary RunReport.md."""
    report_content = f"""# Pipeline Run Report

**Pipeline:** Lapsed Customer Reactivation
**Run ID:** {run_hash}
**Sources:** Supabase, Stripe, Mixpanel, Shopify, Zendesk (5 total)
**Identity Keys:** email (primary), phone (secondary), fuzzy email matching enabled
**Segments:** lapsed_90 (42K), lapsed_vip (4.2K), high_churn_risk (8.5K)
**DQ Rules:** 4 validations (null ratio, uniqueness, schema drift, business logic)
**Activation:** Google Ads (10% holdout), ESP campaigns (A/B test enabled)
**Output:** demo/out/OML.yaml
"""

    report_path = OUT_DIR / "RunReport.md"
    report_path.write_text(report_content)
    return report_path


def main():
    # Start with command prompt
    console.print("\n$ osiris.py chat --interactive\n", style="dim")
    time.sleep(0.8)

    # Agent boot
    agent_say("Osiris Agent v2.1.0 is ready.")
    agent_say(
        "Sub-agents: Connector Builder, Discovery, Identity Resolution, Feature Lab, DQ Guardian, Activation Planner."
    )
    agent_say("How can I help you today?")
    time.sleep(0.5)

    # User intent
    user_say("I need to reactivate customers who haven't purchased for 90+ days.")

    # Agent clarification
    agent_say("I understand you want to reactivate lapsed customers (90+ days inactive).")
    agent_say("To maximize effectiveness, I'll need access to these data sources:")
    console.print("  • [cyan]Stripe[/] - payment history and subscription status")
    console.print("  • [cyan]Shopify[/] - order history and product preferences")
    console.print("  • [cyan]Mixpanel[/] - behavioral events and engagement patterns")
    console.print("  • [cyan]Zendesk[/] - support tickets and satisfaction scores")
    console.print("  • [cyan]Supabase[/] - customer master data and attributes")
    time.sleep(0.3)
    agent_say("This will enable identity resolution, RFM scoring, and targeted segmentation.")
    agent_say("Shall we proceed with these sources?")

    # User confirmation
    user_say("Confirm. Let's proceed.")

    # Connection checks
    agent_say("Checking connections...")
    time.sleep(0.8)

    connections = [
        ("Stripe", True),
        ("Mixpanel", True),
        ("Supabase", True),
        ("Zendesk", True),
        ("Shopify", False),
    ]

    for source, status in connections:
        icon = "[green]✅[/]" if status else "[red]❌[/]"
        status_text = "" if status else " [yellow](connector missing)[/]"
        console.print(f"  {source} {icon}{status_text}")
        time.sleep(0.2)

    agent_say("I can scaffold the Shopify connector stub based on docs. Proceed?")
    auto_approve()

    spinner_task("Generating connector stub...", 0.9)
    spinner_task("Registering...", 0.6)

    # Discovery phase
    spinner_task("Running discovery (schema+sample) with privacy guard (PII masked)...", 2.1)
    spinner_task("Identity alignment on keys: email, phone; fuzzy normalization: enabled...", 1.3)
    spinner_task("Feature sketch: RFM, churn_score; Support reasons from Zendesk topics...", 1.5)

    # DAG and OML generation
    spinner_task("Evaluating DAG...", 0.8)
    agent_say(
        "Designing OML plan for multi-source ingest → IR → features → segments → dq → activation → publish..."
    )

    spinner_task("Generating OML structure...", 1.8)

    # Save OML
    oml_path, run_hash = render_oml()
    agent_say(f"OML ready. Writing to {oml_path.relative_to(Path.cwd())}...")
    time.sleep(0.4)
    console.print("[green]Saved.[/]")

    # Generate report
    report_path = generate_run_report(run_hash)
    time.sleep(0.3)

    # Final message
    agent_say("Done. Next steps: open the OML in your editor or push to Git.")
    console.print("\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        console.print("\n[dim]Session terminated.[/]\n")
        sys.exit(0)
